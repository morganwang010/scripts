{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['抢抓机遇务实创新努力推动公司科学发展上水平1月25日，公司三届一次职代会暨2011年工作会议隆重召开。公司113名职工代表齐聚一堂，共商公司发展和电网建设大计']]\n",
    "s2 = '抢抓机遇务实创新努力推动公司科学发展上水平1月25日，公司三届一次职代会暨2011年工作会议隆重召开。公司113名职工代表齐聚一堂，共商公司发展和电网建设大计'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['抢 抓 机 遇务实创新努力推动公司科学发展上水平1月25日，公司三届一次职代会暨2011年工作会议隆重召开。公司113名职工代表齐聚一堂，共商公司发展和电网建设大计'])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2020-11-07 22:16:33,127 - macropodus - INFO - path of dict cache is /data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/cache/macropodus.cache!\n",
      "2020-11-07 22:16:33,127 - seg_basic.py[line:19] - INFO: path of dict cache is /data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/cache/macropodus.cache!\n",
      "2020-11-07 22:16:33,771 - textcleaner.py[line:37] - INFO: 'pattern' package not found; tag filters are not available for English\n",
      "2020-11-07 22:16:33,778 - macropodus - INFO - path of w2v cache is /data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/cache/word2vec_char.cache!\n",
      "2020-11-07 22:16:33,778 - word2vec.py[line:19] - INFO: path of w2v cache is /data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/cache/word2vec_char.cache!\n",
      "2020-11-07 22:16:37,983 - macropodus - INFO - [Errno 2] No such file or directory: '/data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/model/ner_albert_people_1998/vocab.txt'\n",
      "2020-11-07 22:16:37,983 - __init_tf_keras.py[line:55] - INFO: [Errno 2] No such file or directory: '/data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/model/ner_albert_people_1998/vocab.txt'\n",
      "2020-11-07 22:16:37,984 - macropodus - INFO - [Errno 2] No such file or directory: '/data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/model/tag_albert_people_1998/vocab.txt'\n",
      "2020-11-07 22:16:37,984 - __init_tf_keras.py[line:64] - INFO: [Errno 2] No such file or directory: '/data/anaconda3/envs/nlp/lib/python3.6/site-packages/macropodus/data/model/tag_albert_people_1998/vocab.txt'\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import macropodus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = \"抢抓机遇务实创新努力推动公司科学发展上水平1月25日，公司三届一次职代会暨2011年工作会议隆重召开。公司113名职工代表齐聚一堂，共商公司发展和电网建设大计。天津市电力公司常委、滨海供电分公司总经理闫卫国作了题为《抢抓机遇务实创新努力推动公司科学发展上水平》的工作报告。公司领导班子成员参加会议。公司三届一次职代会暨2011年工作会议的主要任务是：深入贯彻国家电网公司二届一次职代会暨2011年工作会议精神，认真落实天津市电力公司四届一次职代会暨2011年工作会议要求，全面总结公司2010年及“十一五”工作，科学分析发展形势，安排部署2011年各项任务，动员全体干部职工，统一思想，凝心聚力，抢抓机遇，务实创新，加快实现“两个率先”发展目标，扎实推动公司又好又快发展。闫卫国在报告中全面总结了公司2010年工作。他指出，2010年是“十一五”的收官之年，也是公司进入大型重点供电企业的起步之年。一年来，公司坚决贯彻国家电网公司的决策部署，认真落实天津市电力公司提出的工作思路和具体措施，紧紧围绕“两个率先”发展目标，坚持“高严细实”工作理念，加快建设坚强智能电网，大力提升优质服务水平，积极推进“三个建设”，不断强化安全生产、经营管理和党风廉政建设，各项工作取得显著成效。2010年，公司圆满完成天津市电力公司下达的全部企业负责人业绩考核指标，企业和谐，队伍稳定。安全生产保持稳定,电网建设有序推进,优质服务水平不断提高,企业管理水平稳步提升,企业经营效益明显好转,党建和精神文明建设持续加强。闫卫国深入分析了公司面临的形势和任务。他指出，“十二五”是公司发展的重要机遇期，也是在大型重点供电企业竞相发展态势中脱颖而出的攻坚期。经过“十一五”的发展，我们站在了一个新的历史起点上。展望“十二五”，机遇大于挑战，发展前景广阔。要以科学发展观为统领，认真贯彻落实国家电网公司和天津市电力公司决策部署，确保完成全年各项工作目标，努力推动公司科学发展上水平。一是思想认识要上水平,二是文化建设要上水平,三是管理创新要上水平,四是企业素质要上水平。闫卫国在报告中指出，2011年公司工作总体要求是：以科学发展观统领全局，全面贯彻国家电网公司、天津市电力公司各项决策部署，牢牢把握滨海新区开发开放的历史性机遇，紧紧围绕“两个率先”发展目标，坚持“高严细实”工作理念，加快建设坚强智能电网，落实“三集五大”工作要求，切实加强“三个建设”，深入推进“两个转变”，抢抓机遇，务实创新，确保完成全年各项工作任务，努力推动公司科学发展上水平。闫卫国对公司2011年重点工作进行了部署。一是持续巩固安全生产稳定局面，强化安全生产全过程管理，加强电网运行设备管理。二是加快推进坚强智能电网建设，加大规划和前期工作力度，提高项目管理水平，营造良好电网发展环境。三是努力提高企业经营效益，深化经营管理体系建设，千方百计增供扩销，强化集体企业规范发展，坚持依法从严治企。四是不断提升优质服务水平，夯实服务基础，优化服务功能，抓好行风建设。五是全面提升企业管理水平，深化人财物集约化管理，做好公司发展规划，强化信息化建设和科技创新。六是大力实施人才强企战略，强化全员绩效管理和职工素质培训。七是深入推进“三个建设”，进一步加强党的建设、党风廉政建设、企业文化建设，加强职工民主管理，建设优秀员工队伍\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " jieba.load_userdict(\"/media/morgan/d/huawei/nlp/word2vec-tutorial/jieba_dict/dict.txt.big\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter()\n",
    "re_sen = re.compile('[,，\"“”、<>《》{}【】:;!?。：；？！\\n\\r]') #.不加是因为不确定.是小数还是英文句号(中文省略号......)\n",
    "sentences = re_sen.split(s3)\n",
    "sen_cuts = []\n",
    "for sen in sentences:\n",
    "    if sen and str(sen).strip():\n",
    "        sen_cuts.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = []\n",
    "for text in sen_cuts:\n",
    "    for i in range(len(text)):\n",
    "        ngrams += [text[i: j + i]\n",
    "                    for j in range(1, min(6 + 1, len(text) - i + 1))]\n",
    "        words_count.update(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_select = {word: count for word, count in words_count.items()\n",
    "                             if count >= 2 and \" \" not in word\n",
    "                             and 1 < len(word) <= 6\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_entropy = {}\n",
    "left_entropy = {}\n",
    "one_collect = {}\n",
    "total_words_len = {}\n",
    "boundary_type = \"right\"\n",
    "for k, v in words_count.items():\n",
    "        len_k = len(k)\n",
    "        if len_k >= 2:  # 词长度大于3\n",
    "            if boundary_type == \"left\":\n",
    "                k_boundary = k[:-1]\n",
    "            else:\n",
    "                k_boundary = k[1:]\n",
    "            # 左右边, 保存为dict, 左右丰度\n",
    "            #print(k_boundary)\n",
    "            if k_boundary in words_count:\n",
    "                if k_boundary not in one_collect:\n",
    "                    one_collect[k_boundary] = [v]\n",
    "                else:\n",
    "                    one_collect[k_boundary] = one_collect[k_boundary] + [v]\n",
    "        # 计算n-gram的长度\n",
    "        if len_k not in total_words_len:\n",
    "            total_words_len[len_k] = [v]\n",
    "        else:\n",
    "            total_words_len[len_k] += [v]\n",
    "total_words_len = dict([(k, sum(v)) for k,v in total_words_len.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import stop_words\n",
    "import math\n",
    "empty_words = [sw for sw in stop_words.values() if len(sw)==1] # 虚词\n",
    "#print(empty_words)\n",
    "for k, v in words_select.items():\n",
    "    # 从字典获取\n",
    "    boundary_v = one_collect.get(k, None)\n",
    "    # 计算候选词的左右凝固度, 取最小的那个\n",
    "    #print(boundary_v)\n",
    "    if boundary_v:\n",
    "        # 求和\n",
    "        sum_boundary = sum(boundary_v)\n",
    "        # 计算信息熵\n",
    "        entroy_boundary = sum([-(enum_bo / sum_boundary) * math.log(enum_bo / sum_boundary, 2)\n",
    "                                for enum_bo in boundary_v])\n",
    "    else:\n",
    "        entroy_boundary = 0.0\n",
    "    # 惩罚虚词开头或者结尾\n",
    "    if (k[0] in empty_words or k[-1] in empty_words):\n",
    "        entroy_boundary = entroy_boundary / len(k)\n",
    "    if boundary_type == \"right\":\n",
    "        right_entropy[k] = round(entroy_boundary, 6)\n",
    "    else:\n",
    "        left_entropy[k] = round(entroy_boundary, 6)\n",
    "       # print(left_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "776881\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from operator import mul\n",
    "twl_1 = total_words_len[1] # ngram=1 的所有词频\n",
    "print(twl_1)\n",
    "aggregation = {}\n",
    "for word, value in words_select.items():\n",
    "    len_word = len(word)\n",
    "    twl_n = total_words_len[len_word] # ngram=n 的所有词频\n",
    "    words_freq = [words_count.get(wd, 1) for wd in word]\n",
    "    probability_word = value / twl_n\n",
    "    probability_chars = reduce(mul,([wf for wf in words_freq])) / (twl_1**(len(word)))\n",
    "    pmi = math.log(probability_word / probability_chars, 2)\n",
    "    # AMI=PMI/length_word. 惩罚虚词(避免\"的\", \"得\", \"了\"开头结尾的情况)\n",
    "    word_aggregation = pmi/(len_word**len_word) if (word[0] in empty_words or word[-1] in empty_words) \\\n",
    "                                                else pmi/len_word # pmi / len_word / len_word\n",
    "    aggregation[word] = round(word_aggregation, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "776881\n"
     ]
    }
   ],
   "source": [
    "print(total_words_len[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}